{
    "batch_size": 500,
    "learning_rate": 1e-6,
    "num_epochs": 5000,
    "max_seq_length": 18,
    "num_convolution_layers": 3,
    "layer_hidden_dim": 128,
    "layer1_kernel_size": 5,
    "layer1_dilation": 1,
    "layer2_kernel_size": 7,
    "layer2_dilation": 1,
    "dropout_prob": 0.05,
    "patience": 100
  }
